{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3b0862-d89b-497d-890c-3e73f3b2d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 0: Import libs, create functions\n",
    "# We will need the RBCPath type from the rbclib package to load data from the RBC.\n",
    "from rbclib import RBCPath\n",
    "\n",
    "# We'll also want to load some data directly from the filesystem.\n",
    "from pathlib import Path\n",
    "\n",
    "# We'll want to load/process some of the data using pandas and numpy.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8be722-2861-44b9-8edf-208366d623ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fsdata(participant_id, local_cache_dir=(Path.home() / 'cache')):\n",
    "    \"Loads and returns the dataframe of a PNC participant's FreeSurfer data.\"\n",
    "\n",
    "    # Check that the local_cache_dir exists and make it if it doesn't.\n",
    "    if local_cache_dir is not None:\n",
    "        local_cache_dir = Path(local_cache_dir)\n",
    "        local_cache_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Make the RBCPath and find the appropriate file:\n",
    "    pnc_freesurfer_path = RBCPath(\n",
    "        'rbc://PNC_FreeSurfer/freesurfer',\n",
    "        # We provide the local_cache_dir to the RBCPath object; all paths made\n",
    "        # from this object will use the same cache directory.\n",
    "        local_cache_dir=local_cache_dir)\n",
    "    participant_path = pnc_freesurfer_path / f'sub-{participant_id}'\n",
    "    tsv_path = participant_path / f'sub-{participant_id}_regionsurfacestats.tsv'\n",
    "\n",
    "    # Use pandas to read in the TSV file:\n",
    "    with tsv_path.open('r') as f:\n",
    "        data = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "    # Return the loaded data:\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fe2734-11f7-424b-9946-58dda5b33a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ba46_surfarea(participant_id):\n",
    "    \"\"\"Loads and returns the bilateral Brodmann Area 46 (dlPFC) surface area for a PNC\n",
    "    study participant.\n",
    "    \"\"\"\n",
    "    # First, load the subject's FreeSurfer dataframe:\n",
    "    data = load_fsdata(participant_id)\n",
    "    # Next, find the relevant rows:\n",
    "    row_mask = (data['StructName'] == 'Brodmann.46')\n",
    "    # Then extract and sum the surface areas:\n",
    "    ba46_surfareas = data.loc[row_mask, 'SurfArea']\n",
    "    ba46_surfarea = sum(ba46_surfareas)\n",
    "    # And return this value:\n",
    "    return ba46_surfarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045315f1-9ea5-4b76-a5e4-64eaf79b80e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ba7_surfarea(participant_id):\n",
    "    \"\"\"Loads and returns the bilateral Brodmann Area 7 (post PAR) surface area for a PNC\n",
    "    study participant.\n",
    "    \"\"\"\n",
    "    # First, load the subject's FreeSurfer dataframe:\n",
    "    data = load_fsdata(participant_id)\n",
    "    # Next, find the relevant rows:\n",
    "    row_mask = (data['StructName'] == 'Brodmann.7')\n",
    "    # Then extract and sum the surface areas:\n",
    "    ba7_surfareas = data.loc[row_mask, 'SurfArea']\n",
    "    ba7_surfarea = sum(ba7_surfareas)\n",
    "    # And return this value:\n",
    "    return ba7_surfarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaac10d2-47c4-479f-9799-1b84bc9a734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant meta-data is generally located in the BIDS repository for each\n",
    "# study:\n",
    "rbcdata_path = Path('/home/jovyan/shared/data/RBC')\n",
    "train_filepath = rbcdata_path / 'train_participants.tsv'\n",
    "test_filepath = rbcdata_path / 'test_participants.tsv'\n",
    "\n",
    "# Load the PNC participants TSV files...\n",
    "with train_filepath.open('r') as f:\n",
    "    train_data = pd.read_csv(f, sep='\\t')\n",
    "with test_filepath.open('r') as f:\n",
    "    test_data = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "# We can also concatenate the two datasets into a single dataset of all\n",
    "# study participants:\n",
    "all_data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442ad859-9c76-46aa-8417-9323343a0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading surface areas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141fc974d0674714a0c1577aea5dad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1601)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ba46_surface_area</th>\n",
       "      <th>ba7_surface_area</th>\n",
       "      <th>p_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000393599</td>\n",
       "      <td>3804</td>\n",
       "      <td>8939</td>\n",
       "      <td>0.589907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001970838</td>\n",
       "      <td>4261</td>\n",
       "      <td>9922</td>\n",
       "      <td>-0.659061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007995238</td>\n",
       "      <td>4270</td>\n",
       "      <td>9877</td>\n",
       "      <td>-1.608375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011497669</td>\n",
       "      <td>4277</td>\n",
       "      <td>10654</td>\n",
       "      <td>-1.233807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017092387</td>\n",
       "      <td>3754</td>\n",
       "      <td>9932</td>\n",
       "      <td>-0.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>969649154</td>\n",
       "      <td>4958</td>\n",
       "      <td>11095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>970890500</td>\n",
       "      <td>3542</td>\n",
       "      <td>7647</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>975856179</td>\n",
       "      <td>5185</td>\n",
       "      <td>12200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>984757368</td>\n",
       "      <td>4360</td>\n",
       "      <td>8566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>987544292</td>\n",
       "      <td>4884</td>\n",
       "      <td>8786</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1601 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant_id  ba46_surface_area  ba7_surface_area  p_factor\n",
       "0         1000393599               3804              8939  0.589907\n",
       "1         1001970838               4261              9922 -0.659061\n",
       "2         1007995238               4270              9877 -1.608375\n",
       "3         1011497669               4277             10654 -1.233807\n",
       "4         1017092387               3754              9932 -0.923100\n",
       "...              ...                ...               ...       ...\n",
       "1596       969649154               4958             11095       NaN\n",
       "1597       970890500               3542              7647       NaN\n",
       "1598       975856179               5185             12200       NaN\n",
       "1599       984757368               4360              8566       NaN\n",
       "1600       987544292               4884              8786       NaN\n",
       "\n",
       "[1601 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First load in surface area data for each participant:\n",
    "print(\"Loading surface areas...\")     \n",
    "\n",
    "# We will put the rows in this dictionary of lists as we build the dataframe:\n",
    "all_vars = {\n",
    "    'participant_id': [],\n",
    "    'ba46_surface_area': [],\n",
    "    'ba7_surface_area': [],\n",
    "    'p_factor': []}\n",
    "\n",
    "# We'll display a progress bar `prog` as we go also:\n",
    "from ipywidgets import IntProgress\n",
    "prog = IntProgress(min=0, max=len(all_data))\n",
    "display(prog)\n",
    "\n",
    "# Okay, loop through each row of the `all_data` dataframe, which contains both\n",
    "# training and test subjects, load their BA1 data, and store it in the\n",
    "# all_vars dictionary.\n",
    "for (ii, row) in all_data.iterrows():\n",
    "    # Extract the participant ID and p_factor (which will be NaN for test\n",
    "    # participants).\n",
    "    participant_id = row['participant_id']\n",
    "    p_factor = row['p_factor']\n",
    "    \n",
    "    # Load the surface area for this participant:\n",
    "    try:\n",
    "        surf_area46 = load_ba46_surfarea(participant_id)\n",
    "        surf_area7 = load_ba7_surfarea(participant_id)\n",
    "    except FileNotFoundError:\n",
    "        # Some subjects are just missing the file, so we code them as NaN.\n",
    "        surf_area = np.nan\n",
    "    \n",
    "    # Append the participant ID and their surface area to our dataset:\n",
    "    all_vars['participant_id'].append(participant_id)\n",
    "    all_vars['ba46_surface_area'].append(surf_area46)\n",
    "    all_vars['ba7_surface_area'].append(surf_area7)\n",
    "    all_vars['p_factor'].append(p_factor)\n",
    "    # Increment the progress bar counter:\n",
    "    prog.value += 1\n",
    "\n",
    "# Convert train_vars into a dataframe.\n",
    "all_vars = pd.DataFrame(all_vars)\n",
    "\n",
    "# Extract the training and test subjects into separate dataframes; the test\n",
    "# participants can be identified as those having NaN values for their\n",
    "# p_factor column.\n",
    "train_vars = all_vars[~np.isnan(all_vars['p_factor'])]\n",
    "test_vars = all_vars[np.isnan(all_vars['p_factor'])]\n",
    "\n",
    "# Display the finished dataframe.\n",
    "all_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cf3d8-2cb3-4487-b36d-82b797ca6e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
